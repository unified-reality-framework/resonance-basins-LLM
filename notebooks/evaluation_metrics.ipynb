{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90acae4",
   "metadata": {},
   "source": [
    "# Evaluation Metrics – t-test, CI, and Cohen's d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdbed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation Metrics – t-test, CI, and Cohen's d\n",
    "# This notebook loads (or synthesises) experiment CSVs and computes statistics.\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_dir = \"/mnt/data\"\n",
    "csv_dir = os.path.join(base_dir, \"csv\")\n",
    "\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "# If CSVs are missing, synthesise demo data approximating the paper's numbers.\n",
    "def maybe_make_demo_csv(path, task, baseline_rate, mitigated_rate, n_prompts=2000, n_runs=20, seed=7):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "    for run_id in range(1, n_runs+1):\n",
    "        # Bernoulli samples with slight per-run variance\n",
    "        b = rng.binomial(1, baseline_rate, size=n_prompts)\n",
    "        m = rng.binomial(1, mitigated_rate, size=n_prompts)\n",
    "        for i in range(n_prompts):\n",
    "            rows.append({\n",
    "                \"prompt_id\": f\"{task}_{run_id}_{i+1:04d}\",\n",
    "                \"run_id\": run_id,\n",
    "                \"task\": task,\n",
    "                \"is_hallucination_baseline\": int(b[i]),\n",
    "                \"is_hallucination_mitigated\": int(m[i]),\n",
    "                \"latency_ms\": int(rng.normal(1200, 120).clip(800, 1800)),\n",
    "            })\n",
    "    pd.DataFrame(rows).to_csv(path, index=False)\n",
    "\n",
    "gsm_path = os.path.join(csv_dir, \"gsm8k_results.csv\")\n",
    "tqa_path = os.path.join(csv_dir, \"truthfulqa_results.csv\")\n",
    "\n",
    "maybe_make_demo_csv(gsm_path, \"GSM8K\", baseline_rate=0.38, mitigated_rate=0.29)\n",
    "maybe_make_demo_csv(tqa_path, \"TruthfulQA\", baseline_rate=0.62, mitigated_rate=0.43)\n",
    "\n",
    "# Load and compute stats\n",
    "def compute_stats(path):\n",
    "    df = pd.read_csv(path)\n",
    "    grouped = df.groupby([\"task\",\"run_id\"]).mean(numeric_only=True)\n",
    "    b = grouped[\"is_hallucination_baseline\"].values\n",
    "    m = grouped[\"is_hallucination_mitigated\"].values\n",
    "    # Paired t-test across runs\n",
    "    t_stat, p_val = stats.ttest_rel(b, m)\n",
    "    # Cohen's d for paired samples ~ approximate using pooled SD\n",
    "    d = (b.mean() - m.mean()) / np.sqrt(((b.std(ddof=1)**2 + m.std(ddof=1)**2)/2))\n",
    "    # 95% CI for mean difference\n",
    "    diff = b - m\n",
    "    mean_diff = diff.mean()\n",
    "    se = diff.std(ddof=1) / np.sqrt(len(diff))\n",
    "    ci_low = mean_diff - 1.96*se\n",
    "    ci_high = mean_diff + 1.96*se\n",
    "    return {\n",
    "        \"baseline_mean\": b.mean(), \"mitigated_mean\": m.mean(),\n",
    "        \"mean_diff\": mean_diff, \"ci_95\": (ci_low, ci_high),\n",
    "        \"t_stat\": t_stat, \"p_value\": p_val, \"cohen_d\": d\n",
    "    }\n",
    "\n",
    "gsm_stats = compute_stats(gsm_path)\n",
    "tqa_stats = compute_stats(tqa_path)\n",
    "\n",
    "print(\"GSM8K:\", gsm_stats)\n",
    "print(\"TruthfulQA:\", tqa_stats)\n",
    "\n",
    "# Bar plot of baseline vs mitigated for both tasks\n",
    "labels = [\"GSM8K\", \"TruthfulQA\"]\n",
    "baseline_vals = [gsm_stats[\"baseline_mean\"], tqa_stats[\"baseline_mean\"]]\n",
    "mitig_vals = [gsm_stats[\"mitigated_mean\"], tqa_stats[\"mitigated_mean\"]]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "w = 0.35\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(x - w/2, baseline_vals, width=w, label=\"Baseline\")\n",
    "plt.bar(x + w/2, mitig_vals, width=w, label=\"With Basins\")\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel(\"Hallucination rate (mean across runs)\")\n",
    "plt.title(\"Baseline vs With Basins\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
